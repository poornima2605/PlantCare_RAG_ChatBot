# ğŸŒ¿ PlantCare RAG ChatBot

The **PlantCare RAG ChatBot** is an AI-powered assistant built using Retrieval-Augmented Generation (RAG) that provides helpful information and personalized advice on plant care. Whether you're a seasoned gardener or a houseplant newbie, this chatbot leverages natural language processing to answer your questions based on custom plant care documents and models.

---

## ğŸš€ Features

- ğŸŒ± **Plant care Q&A**: Ask questions about watering, light, soil, and more.
- ğŸ” **Retrieval-Augmented Generation (RAG)**: Combines vector search with LLMs to provide accurate and grounded answers.
- ğŸ§  **Sentence-BERT embeddings**: For high-quality semantic search using the `all-MiniLM-L6-v2` model.
- ğŸ“ **Custom document support**: Easily extend knowledge base with your own plant care files.
- âš¡ **FastAPI + Uvicorn backend**: Lightweight and production-ready API.

---

## ğŸ§© System Architecture

![System Architecture](https://airbyte.com/data-engineering-resources/rag-architecure-with-generative-ai)

**Components:**
- User sends a question via frontend or API.
- FastAPI handles the request and passes it to the retriever.
- Retriever uses Sentence-BERT to embed the query.
- VectorStore retrieves relevant documents.
- Retrieved context is passed to the LLM for answer generation.

---

## ğŸ”„ Request Flow

![Request Flow](https://medium.com/credera-engineering/build-a-simple-rag-chatbot-with-langchain-b96b233e1b2a)
1. User submits a plant care question.
2. Question is embedded using Sentence-BERT.
3. Vector search finds relevant context.
4. Context + question are passed to the language model.
5. Response is returned via the FastAPI endpoint.

---

## ğŸ—ï¸ Project Structure

PlantCare_RAG_ChatBot/ 
â”œâ”€â”€ app/ 
â”‚ â”œâ”€â”€ api.py # FastAPI app and routes 
â”‚ â”œâ”€â”€ retriever.py # Vector search logic 
â”‚ â”œâ”€â”€ vectorstore.py # Embedding & storage using Sentence-BERT 
â”‚ â””â”€â”€ documents/ # Plant care text data 
â”œâ”€â”€ Dockerfile # Container setup 
â”œâ”€â”€ requirements.txt # Python dependencies 
â””â”€â”€ README.md # Project info

---

## ğŸ› ï¸ Setup & Installation

### Prerequisites:

1. Python 3.9+
2. Docker
3. OpenAI API Keyâ€‹


### Steps:

#### Step 1: Clone the Repository:

git clone https://github.com/yourusername/plantcare-rag-chatbot.git
cd plantcare-rag-chatbot

#### Step 2: Set Up Environment Variables:

Create a .env file in the root directory and add your OpenAI API key:

OPENAI_API_KEY=your_openai_api_key

#### Step 3: Build the Docker image

docker build -t plant-bot .

#### Step 4: Run the container

docker run -p 8000:8000 plant-bot

---

## ğŸ’¬ Usage

Once the application is running, navigate to http://localhost:8000 in your browser. Enter your plant care questions, and the chatbot will provide informed responses based on the integrated knowledge base.

### ğŸ§ª API Usage Example

Endpoint: /query
Method: POST
Payload:

{
  "question": "How often should I water a snake plant?"
}

Response:

{
  "answer": "Snake plants prefer to dry out completely between waterings. Water once every 2-3 weeks."
}

---

## ğŸ§° Tech Stack

1. **FastAPI**: Web framework for building APIs
2. **Uvicorn**: ASGI server FastAPI server
3. **Sentence-Transformers**: all-MiniLM-L6-v2 for semantic embeddings
4. **HuggingFace Transformers**
5. **Docker**: Containerized deployment

---

## ğŸ“„ Customizing the Knowledge Base

1. Add your .txt to the app/documents/ directory.
2. Rebuild the vector store by running app/create_index.py "path_to_new_txt".
3. Restart the app to load new embeddings.